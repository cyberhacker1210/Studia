==================================================
EXPORT CIBL√â (8 fichiers)
Dossiers inclus : app, components, backend, src/app, src/components, server, api
==================================================

SOMMAIRE :
- backend/src/__init__.py
- backend/src/toto.py
- backend/src/studia/quiz_generator.py
- backend/src/studia/__init__.py
- backend/src/studia/flashcard_generator.py
- backend/src/studia/settings.py
- backend/src/studia/learning_path.py
- backend/src/studia/main.py

==================================================

--- FICHIER : backend/src/__init__.py (1 lignes) ---


------------------------------

--- FICHIER : backend/src/toto.py (7 lignes) ---

tutu = {
  "quiz": {
      "question": "Comment la production est-elle d√©finie selon le cours ?",
      "answer": "La production est une activit√© socialement organis√©e qui permet de cr√©er des biens et des services."
  }
}

------------------------------

--- FICHIER : backend/src/studia/quiz_generator.py (551 lignes) ---
"""
Quiz Generator - Extract text from images and generate MCQ quizzes with SELF-REFINING
"""
import os
import re
import json
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

# OpenAI Client
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)


def extract_text(image_base64: str) -> str:
    """
    üîÑ STEP 1: Extract text from image using GPT-4 Vision
    """

    prompt = """Extract ALL the text from this image with maximum accuracy.

RULES:
- Extract EVERYTHING: titles, paragraphs, lists, formulas, tables, diagrams labels
- Preserve the structure (use line breaks and spacing)
- Do NOT add any comments or explanations
- If mathematical formulas, write them clearly
- If tables, format them readably
- If handwritten, do your best to transcribe accurately

Return ONLY the extracted text, nothing else."""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": prompt
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}"
                        },
                    },
                ],
            }
        ],
    )

    extracted_text = response.choices[0].message.content
    print(f"‚úÖ Text extracted: {len(extracted_text)} characters")
    return extracted_text


def verify_and_refine_extraction(image_base64: str, extracted_text: str) -> dict:
    """
    üîÑ STEP 2: Verify extraction accuracy and refine if needed
    """

    print("üîç Verifying text extraction accuracy...")

    verification_prompt = f"""You are a text extraction quality validator. Return your analysis in JSON format.

Compare the EXTRACTED TEXT with the ORIGINAL IMAGE and check:

1. Are all visible words captured?
2. Is the structure preserved (paragraphs, lists, etc.)?
3. Are formulas/equations transcribed correctly?
4. Are there any obvious errors or missing parts?
5. Is the text readable and makes sense?

EXTRACTED TEXT:
{extracted_text}

Return ONLY valid JSON:
{{
  "is_accurate": true or false,
  "confidence_score": 0-100,
  "issues": [
    {{
      "type": "missing_text/wrong_transcription/formatting_error",
      "severity": "high/medium/low",
      "description": "What's wrong",
      "location": "Where in the text"
    }}
  ],
  "needs_refinement": true or false,
  "general_assessment": "Brief overall evaluation"
}}

If confidence_score < 85%, set needs_refinement = true
Return ONLY valid JSON, nothing else."""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": verification_prompt
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}"
                        },
                    },
                ],
            }
        ],
    )

    verification = json.loads(response.choices[0].message.content)
    print(f"   Confidence: {verification.get('confidence_score', 0)}%")
    print(f"   Issues found: {len(verification.get('issues', []))}")

    # If needs refinement, do a second extraction with more focus
    if verification.get('needs_refinement', False):
        print("üîß Refining text extraction...")

        issues_description = "\n".join([
            f"- {issue['description']}" for issue in verification.get('issues', [])
        ])

        refine_prompt = f"""Re-extract the text from this image with EXTRA CARE.

PREVIOUS EXTRACTION HAD THESE ISSUES:
{issues_description}

PREVIOUS EXTRACTED TEXT (for reference):
{extracted_text}

Now extract the text again, fixing these issues:
- Be more careful with formulas and special characters
- Check for missing sections
- Verify formatting and structure
- Double-check numbers and technical terms

Return ONLY the corrected extracted text, nothing else."""

        refine_response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": refine_prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            },
                        },
                    ],
                }
            ],
        )

        refined_text = refine_response.choices[0].message.content
        print(f"‚úÖ Text refined: {len(refined_text)} characters")

        verification['refined_text'] = refined_text
        verification['was_refined'] = True
    else:
        verification['refined_text'] = extracted_text
        verification['was_refined'] = False

    return verification


def validate_quiz_quality(course_text: str, quiz_data: dict) -> dict:
    """
    üîÑ STEP 3: Validate quiz quality and accuracy
    """

    validation_prompt = f"""You are a quiz quality validator. Analyze this quiz and return your analysis in JSON format.

ORIGINAL COURSE TEXT:
{course_text}

GENERATED QUIZ:
{json.dumps(quiz_data, indent=2, ensure_ascii=False)}

CHECK THE FOLLOWING:
1. Are ALL questions based on FACTS from the course? (not general knowledge)
2. Are the correct answers ACCURATE according to the course text?
3. Are the incorrect options plausible but clearly wrong?
4. Are the explanations clear and refer to the course?
5. Is the difficulty level appropriate?
6. Do the questions test actual understanding (not just memorization)?

Return ONLY valid JSON in this exact format:
{{
  "is_valid": true or false,
  "accuracy_score": 0-100,
  "issues": [
    {{
      "question_index": 0,
      "severity": "high/medium/low",
      "issue": "Description of the problem",
      "suggestion": "How to fix it"
    }}
  ],
  "general_feedback": "Overall assessment"
}}

CRITICAL RULES:
- If a question uses info NOT in the course: is_valid = false
- If correctAnswer is wrong: is_valid = false
- accuracy_score = percentage of questions that are perfectly accurate
- Return ONLY valid JSON"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[
            {
                "role": "user",
                "content": validation_prompt
            }
        ],
    )

    validation_result = json.loads(response.choices[0].message.content)

    print(f"üîç Quiz Validation Score: {validation_result.get('accuracy_score', 0)}%")
    print(f"   Issues found: {len(validation_result.get('issues', []))}")

    return validation_result


def refine_quiz(course_text: str, quiz_data: dict, validation_result: dict) -> dict:
    """
    üîß STEP 4: Fix issues found in quiz validation
    """

    if validation_result.get('is_valid', False) and validation_result.get('accuracy_score', 0) >= 90:
        print("‚úÖ Quiz quality is excellent, no refinement needed")
        return quiz_data

    print("üîß Refining quiz based on validation feedback...")

    refine_prompt = f"""You are a quiz refinement expert. FIX the issues in this quiz and return valid JSON.

ORIGINAL COURSE TEXT:
{course_text}

CURRENT QUIZ (with issues):
{json.dumps(quiz_data, indent=2, ensure_ascii=False)}

VALIDATION ISSUES:
{json.dumps(validation_result.get('issues', []), indent=2, ensure_ascii=False)}

YOUR TASK:
1. Fix EVERY issue mentioned
2. Ensure ALL questions are based ONLY on the course text
3. Verify correct answers are accurate
4. Improve explanations to reference the course
5. Make sure incorrect options are plausible but definitely wrong

Return ONLY the CORRECTED quiz in this EXACT JSON format:
{{
  "questions": [
    {{
      "question": "...",
      "options": ["...", "...", "...", "..."],
      "correctAnswer": 0,
      "explanation": "..."
    }}
  ]
}}

CRITICAL: Base EVERYTHING on the course text. NO external information. Return ONLY valid JSON."""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[
            {
                "role": "user",
                "content": refine_prompt
            }
        ],
    )

    refined_quiz = json.loads(response.choices[0].message.content)
    print("‚úÖ Quiz refined successfully")

    return refined_quiz


def generate_quiz_mcq(
        course_text: str,
        num_questions: int,
        difficulty: str
) -> dict:
    """Generate MCQ quiz from course text"""

    difficulty_instructions = {
        "easy": "Les questions doivent √™tre simples et directes, adapt√©es aux d√©butants.",
        "medium": "Les questions doivent √™tre de difficult√© moyenne, n√©cessitant une bonne compr√©hension du cours.",
        "hard": "Les questions doivent √™tre difficiles et exiger une connaissance approfondie du cours."
    }

    prompt = f"""Tu es un assistant qui r√©pond toujours et juste en JSON. Pas de texte parasite, que du JSON.

Cr√©e un quiz de {num_questions} questions √† choix multiples (QCM) bas√© UNIQUEMENT sur ce cours.

COURS:
{course_text}

DIFFICULT√â: {difficulty}
{difficulty_instructions[difficulty]}

Le JSON doit √™tre EXACTEMENT comme ceci:
{{
  "questions": [
    {{
      "question": "Quelle est la formule de la production mentionn√©e dans le cours?",
      "options": [
        "Production = Travail + Machines + Al√©a",
        "Production = Capital + Travail",
        "Production = Co√ªt + B√©n√©fice",
        "Production = Offre + Demande"
      ],
      "correctAnswer": 0,
      "explanation": "Selon le cours, la formule exacte est Production = Travail + Machines + Al√©a"
    }}
  ]
}}

R√àGLES CRITIQUES:
- Exactement {num_questions} questions
- Chaque question a EXACTEMENT 4 options
- correctAnswer est l'index de la bonne r√©ponse (0, 1, 2, ou 3)
- VARIE les positions: ne mets pas toujours correctAnswer √† 0
- Les options incorrectes doivent √™tre plausibles mais clairement fausses
- Chaque question doit avoir une "explanation" courte qui CITE le cours
- Base-toi UNIQUEMENT sur le contenu du cours fourni (pas de connaissances externes)
- Les questions doivent √™tre PR√âCISES et V√âRIFIABLES dans le cours
- Pas de texte avant ou apr√®s le JSON, UNIQUEMENT le JSON
"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[
            {
                "role": "user",
                "content": prompt
            }
        ],
    )

    quiz_data = json.loads(response.choices[0].message.content)
    print("‚úÖ Initial quiz generated")

    return quiz_data


def quiz_generator_from_image(
        image_base64: str,
        num_questions: int = 5,
        difficulty: str = "medium",
        enable_refinement: bool = True
) -> dict:
    """
    Generate quiz from course image with COMPLETE SELF-REFINING
    """

    print(f"üì∏ Quiz generation started (Self-Refining: {'ON' if enable_refinement else 'OFF'})")
    print(f"   Parameters: {num_questions} questions, difficulty: {difficulty}")

    try:
        # üîÑ STEP 1: Extract text from image
        print("\n1Ô∏è‚É£ Extracting text from image...")
        course_text = extract_text(image_base64)

        if not course_text or len(course_text.strip()) < 10:
            raise ValueError("Failed to extract text from image or text too short")

        extraction_metadata = {
            "initial_length": len(course_text),
            "was_refined": False,
            "confidence_score": 100
        }

        # üîÑ STEP 2: Verify and refine extraction (if enabled)
        if enable_refinement:
            print("\n2Ô∏è‚É£ Verifying text extraction...")
            verification = verify_and_refine_extraction(image_base64, course_text)

            if verification.get('was_refined', False):
                course_text = verification['refined_text']
                print(f"   ‚úÖ Text was refined (confidence: {verification.get('confidence_score', 0)}%)")

            extraction_metadata = {
                "initial_length": extraction_metadata["initial_length"],
                "final_length": len(course_text),
                "was_refined": verification.get('was_refined', False),
                "confidence_score": verification.get('confidence_score', 0),
                "issues_found": len(verification.get('issues', []))
            }

        # üîÑ STEP 3: Generate quiz
        print(f"\n3Ô∏è‚É£ Generating quiz ({num_questions} questions, {difficulty})...")
        quiz_data = generate_quiz_mcq(course_text, num_questions, difficulty)

        # Validate structure
        if "questions" not in quiz_data:
            raise ValueError("Invalid quiz format: missing 'questions' key")

        # Validate each question
        for i, q in enumerate(quiz_data["questions"]):
            if "question" not in q:
                raise ValueError(f"Question {i + 1}: missing 'question' field")
            if "options" not in q or len(q["options"]) != 4:
                raise ValueError(f"Question {i + 1}: must have exactly 4 options")
            if "correctAnswer" not in q:
                raise ValueError(f"Question {i + 1}: missing 'correctAnswer' field")
            if not (0 <= q["correctAnswer"] <= 3):
                raise ValueError(f"Question {i + 1}: correctAnswer must be 0-3")
            if "explanation" not in q:
                q["explanation"] = ""

        # üîÑ STEP 4: Validate and refine quiz (if enabled)
        quiz_metadata = {
            "was_refined": False,
            "initial_score": 100,
            "final_score": 100
        }

        if enable_refinement:
            print("\n4Ô∏è‚É£ Validating quiz quality...")
            validation_result = validate_quiz_quality(course_text, quiz_data)

            quiz_metadata["initial_score"] = validation_result.get('accuracy_score', 0)

            # If validation fails or score is low, refine
            if not validation_result.get('is_valid', False) or validation_result.get('accuracy_score', 0) < 90:
                print("\n5Ô∏è‚É£ Refining quiz...")
                quiz_data = refine_quiz(course_text, quiz_data, validation_result)

                # Re-validate after refinement
                print("\n6Ô∏è‚É£ Re-validating refined quiz...")
                final_validation = validate_quiz_quality(course_text, quiz_data)

                quiz_metadata["final_score"] = final_validation.get('accuracy_score', 0)
                quiz_metadata["was_refined"] = True

                print(f"   ‚úÖ Quiz refined (score: {quiz_metadata['initial_score']}% ‚Üí {quiz_metadata['final_score']}%)")
            else:
                quiz_metadata["final_score"] = validation_result.get('accuracy_score', 0)
                quiz_metadata["was_refined"] = False
                print(f"   ‚úÖ Quiz quality is good ({quiz_metadata['final_score']}%)")

        # ‚ú® Add metadata to result
        quiz_data["extractedText"] = course_text
        quiz_data["metadata"] = {
            "extraction": extraction_metadata,
            "quiz_quality": quiz_metadata,
            "self_refining_enabled": enable_refinement
        }

        print(f"\n‚úÖ FINAL RESULT:")
        print(f"   Questions: {len(quiz_data['questions'])}")
        print(f"   Text length: {len(course_text)} characters")
        if enable_refinement:
            print(f"   Text confidence: {extraction_metadata.get('confidence_score', 'N/A')}%")
            print(f"   Quiz quality: {quiz_metadata.get('final_score', 'N/A')}%")
            print(f"   Refinements: Text={extraction_metadata.get('was_refined', False)}, Quiz={quiz_metadata.get('was_refined', False)}")

        return quiz_data

    except json.JSONDecodeError as e:
        print(f"‚ùå JSON Parse Error: {e}")
        raise Exception(f"Failed to parse quiz JSON: {str(e)}")
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        raise


def quiz_generator_from_text(
        course_text: str,
        num_questions: int = 5,
        difficulty: str = "medium",
        enable_refinement: bool = True
) -> dict:
    """
    Generate quiz from course text with SELF-REFINING
    """

    print(f"üìù Quiz generation from text (Self-Refining: {'ON' if enable_refinement else 'OFF'})")

    try:
        # Generate quiz
        print("1Ô∏è‚É£ Generating quiz...")
        quiz_data = generate_quiz_mcq(course_text, num_questions, difficulty)

        # Validate structure
        if "questions" not in quiz_data:
            raise ValueError("Invalid quiz format: missing 'questions' key")

        quiz_metadata = {
            "was_refined": False,
            "initial_score": 100,
            "final_score": 100
        }

        # Validate and refine (if enabled)
        if enable_refinement:
            print("2Ô∏è‚É£ Validating quiz quality...")
            validation_result = validate_quiz_quality(course_text, quiz_data)

            quiz_metadata["initial_score"] = validation_result.get('accuracy_score', 0)

            if not validation_result.get('is_valid', False) or validation_result.get('accuracy_score', 0) < 90:
                print("3Ô∏è‚É£ Refining quiz...")
                quiz_data = refine_quiz(course_text, quiz_data, validation_result)

                final_validation = validate_quiz_quality(course_text, quiz_data)
                quiz_metadata["final_score"] = final_validation.get('accuracy_score', 0)
                quiz_metadata["was_refined"] = True
            else:
                quiz_metadata["final_score"] = validation_result.get('accuracy_score', 0)

        quiz_data["metadata"] = {
            "quiz_quality": quiz_metadata,
            "self_refining_enabled": enable_refinement
        }

        print(f"‚úÖ Quiz generated: {len(quiz_data['questions'])} questions")
        if enable_refinement:
            print(f"   Quality score: {quiz_metadata.get('final_score', 'N/A')}%")

        return quiz_data

    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        raise

------------------------------

--- FICHIER : backend/src/studia/__init__.py (4 lignes) ---
"""
Studia - AI-powered learning platform
"""
__version__ = "1.0.0"

------------------------------

--- FICHIER : backend/src/studia/flashcard_generator.py (316 lignes) ---
"""
Flashcard Generator - Generate flashcards from course text with SELF-REFINING
"""
import json
import re
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def validate_flashcards_quality(course_text: str, flashcards_data: dict) -> dict:
    """
    üîÑ STEP 1: Validate flashcard quality and accuracy

    Returns:
    {
        "is_valid": bool,
        "quality_score": 0-100,
        "issues": [...],
        "general_feedback": str
    }
    """

    print("üîç Validating flashcards quality...")

    validation_prompt = f"""You are a flashcard quality validator. Analyze these flashcards and return your analysis in JSON format.

ORIGINAL COURSE TEXT:
{course_text}

GENERATED FLASHCARDS:
{json.dumps(flashcards_data, indent=2, ensure_ascii=False)}

CHECK THE FOLLOWING:
1. Is each "front" (question/concept) based on actual content from the course?
2. Is each "back" (answer) ACCURATE according to the course text?
3. Are the flashcards testing KEY concepts (not trivial/useless facts)?
4. Is the information complete but concise on the "back"?
5. Are there any duplicates or very similar cards?
6. Is the difficulty level appropriate?
7. Are formulas/technical terms correctly written?

Return ONLY valid JSON in this exact format:
{{
  "is_valid": true or false,
  "quality_score": 0-100,
  "issues": [
    {{
      "card_index": 0,
      "severity": "high/medium/low",
      "issue": "Description of the problem",
      "suggestion": "How to fix it"
    }}
  ],
  "general_feedback": "Overall assessment of the flashcards quality"
}}

CRITICAL RULES:
- If a flashcard uses info NOT in the course: is_valid = false, high severity
- If an answer is incomplete or wrong: is_valid = false, high severity
- quality_score = percentage of flashcards that are perfectly accurate and useful
- List ALL issues found, even small ones
- Return ONLY valid JSON"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[
            {
                "role": "user",
                "content": validation_prompt
            }
        ],
    )

    validation_result = json.loads(response.choices[0].message.content)

    print(f"   Quality Score: {validation_result.get('quality_score', 0)}%")
    print(f"   Issues found: {len(validation_result.get('issues', []))}")

    return validation_result


def refine_flashcards(course_text: str, flashcards_data: dict, validation_result: dict) -> dict:
    """
    üîß STEP 2: Fix issues found in flashcard validation
    """

    if validation_result.get('is_valid', False) and validation_result.get('quality_score', 0) >= 90:
        print("‚úÖ Flashcards quality is excellent, no refinement needed")
        return flashcards_data

    print("üîß Refining flashcards based on validation feedback...")

    refine_prompt = f"""You are a flashcard refinement expert. FIX the issues in these flashcards and return valid JSON.

ORIGINAL COURSE TEXT:
{course_text}

CURRENT FLASHCARDS (with issues):
{json.dumps(flashcards_data, indent=2, ensure_ascii=False)}

VALIDATION ISSUES:
{json.dumps(validation_result.get('issues', []), indent=2, ensure_ascii=False)}

YOUR TASK:
1. Fix EVERY issue mentioned
2. Ensure ALL flashcards are based ONLY on the course text
3. Verify answers are complete and accurate
4. Remove duplicates if any
5. Make sure "front" is clear and "back" is comprehensive but concise

Return ONLY the CORRECTED flashcards in this EXACT JSON format:
{{
  "flashcards": [
    {{
      "front": "Question/Concept",
      "back": "Complete and accurate answer",
      "category": "Category name",
      "difficulty": "easy/medium/hard"
    }}
  ]
}}

RULES:
- Keep the SAME number of flashcards
- Base EVERYTHING on the course text
- Do NOT add external information
- Make answers specific and complete
- "front" should be short (1 sentence max)
- "back" should be concise but complete (2-3 sentences)
- Return ONLY valid JSON, nothing else"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[
            {
                "role": "user",
                "content": refine_prompt
            }
        ],
    )

    refined_flashcards = json.loads(response.choices[0].message.content)
    print("‚úÖ Flashcards refined successfully")

    return refined_flashcards


def generate_flashcards(
        course_text: str,
        num_cards: int = 10,
        difficulty: str = "medium",
        enable_refinement: bool = True
) -> dict:
    """
    Generate flashcards from course text with SELF-REFINING

    Args:
        course_text: Text extracted from course
        num_cards: Number of flashcards to generate
        difficulty: easy, medium, or hard
        enable_refinement: Enable self-refining validation (default: True)

    Returns:
        dict: Flashcards data with metadata
    """

    print(f"üé¥ Flashcard generation started (Self-Refining: {'ON' if enable_refinement else 'OFF'})")
    print(f"   Parameters: {num_cards} cards, difficulty: {difficulty}")

    try:
        # STEP 1: Generate initial flashcards
        print("\n1Ô∏è‚É£ Generating initial flashcards...")

        difficulty_instructions = {
            "easy": "Les flashcards doivent couvrir les concepts de base et les d√©finitions simples.",
            "medium": "Les flashcards doivent aborder des concepts interm√©diaires et leurs applications.",
            "hard": "Les flashcards doivent inclure des concepts avanc√©s et des relations complexes."
        }

        prompt = f"""Tu es un assistant qui r√©pond toujours et juste en JSON. Pas de texte parasite, que du JSON.

Cr√©e {num_cards} flashcards (cartes m√©moire) bas√©es UNIQUEMENT sur ce cours.

COURS:
{course_text}

DIFFICULT√â: {difficulty}
{difficulty_instructions[difficulty]}

Le JSON doit √™tre EXACTEMENT comme ceci:
{{
  "flashcards": [
    {{
      "front": "Qu'est-ce que la photosynth√®se ?",
      "back": "La photosynth√®se est le processus par lequel les plantes convertissent la lumi√®re du soleil en √©nergie chimique.",
      "category": "Biologie",
      "difficulty": "{difficulty}"
    }},
    {{
      "front": "Formule de la photosynth√®se",
      "back": "6CO‚ÇÇ + 6H‚ÇÇO + lumi√®re ‚Üí C‚ÇÜH‚ÇÅ‚ÇÇO‚ÇÜ + 6O‚ÇÇ",
      "category": "Biologie",
      "difficulty": "{difficulty}"
    }}
  ]
}}

R√àGLES CRITIQUES:
- Exactement {num_cards} flashcards
- Chaque flashcard a :
  * "front" : la question/concept (court et clair, 1 phrase max)
  * "back" : la r√©ponse/explication (compl√®te mais concise, 2-3 phrases)
  * "category" : cat√©gorie du sujet (ex: Math√©matiques, Histoire, etc.)
  * "difficulty" : "{difficulty}"
- Varie les types : d√©finitions, formules, concepts, applications, processus
- Les r√©ponses doivent √™tre PR√âCISES et V√âRIFIABLES dans le cours
- Base-toi UNIQUEMENT sur le contenu du cours fourni (pas de connaissances externes)
- Pas de texte avant ou apr√®s le JSON, UNIQUEMENT le JSON
- Teste des concepts IMPORTANTS, pas des d√©tails insignifiants
"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            response_format={"type": "json_object"},
            messages=[
                {
                    "role": "user",
                    "content": [{"type": "text", "text": prompt}]
                }
            ],
        )

        flashcards_json = response.choices[0].message.content

        # Clean JSON
        flashcards_json = re.sub(r"```json\n?", "", flashcards_json)
        flashcards_json = re.sub(r"```\n?", "", flashcards_json)

        # Parse JSON
        flashcards_data = json.loads(flashcards_json.strip())

        # STEP 2: Validate structure
        if "flashcards" not in flashcards_data:
            raise ValueError("Invalid flashcards format: missing 'flashcards' key")

        if len(flashcards_data["flashcards"]) != num_cards:
            print(f"‚ö†Ô∏è Warning: Expected {num_cards} flashcards, got {len(flashcards_data['flashcards'])}")

        for i, card in enumerate(flashcards_data["flashcards"]):
            if "front" not in card or "back" not in card:
                raise ValueError(f"Flashcard {i + 1}: missing 'front' or 'back' field")
            if "category" not in card:
                card["category"] = "G√©n√©ral"
            if "difficulty" not in card:
                card["difficulty"] = difficulty

        print(f"‚úÖ Initial flashcards generated: {len(flashcards_data['flashcards'])}")

        # üîÑ STEP 3: SELF-REFINING (if enabled)
        metadata = {
            "was_refined": False,
            "initial_score": 100,
            "final_score": 100
        }

        if enable_refinement:
            print("\n2Ô∏è‚É£ Validating flashcards quality...")
            validation_result = validate_flashcards_quality(course_text, flashcards_data)

            metadata["initial_score"] = validation_result.get('quality_score', 0)

            # If validation fails or score is low, refine
            if not validation_result.get('is_valid', False) or validation_result.get('quality_score', 0) < 90:
                print("\n3Ô∏è‚É£ Refining flashcards...")
                flashcards_data = refine_flashcards(course_text, flashcards_data, validation_result)

                # Re-validate after refinement
                print("\n4Ô∏è‚É£ Re-validating refined flashcards...")
                final_validation = validate_flashcards_quality(course_text, flashcards_data)

                metadata["final_score"] = final_validation.get('quality_score', 0)
                metadata["was_refined"] = True

                print(f"   ‚úÖ Flashcards refined (score: {metadata['initial_score']}% ‚Üí {metadata['final_score']}%)")
            else:
                metadata["final_score"] = validation_result.get('quality_score', 0)
                metadata["was_refined"] = False
                print(f"   ‚úÖ Flashcards quality is good ({metadata['final_score']}%)")

        # ‚ú® Add metadata to result
        flashcards_data["metadata"] = {
            "quality": metadata,
            "self_refining_enabled": enable_refinement
        }

        print(f"\n‚úÖ FINAL RESULT:")
        print(f"   Flashcards: {len(flashcards_data['flashcards'])}")
        if enable_refinement:
            print(f"   Quality score: {metadata.get('final_score', 'N/A')}%")
            print(f"   Refined: {metadata.get('was_refined', False)}")

        return flashcards_data

    except json.JSONDecodeError as e:
        print(f"‚ùå JSON Parse Error: {e}")
        raise Exception(f"Failed to parse flashcards JSON: {str(e)}")
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        raise

------------------------------

--- FICHIER : backend/src/studia/settings.py (8 lignes) ---
import os

# OpenAI Configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Server Configuration
API_HOST = os.getenv("API_HOST", "0.0.0.0")
API_PORT = int(os.getenv("API_PORT", 5000))

------------------------------

--- FICHIER : backend/src/studia/learning_path.py (65 lignes) ---
"""
Learning Path, Motivator & Chat Generator
"""
import json
import os
from typing import List
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def generate_mastery_path(course_text: str) -> dict:
    print("üß¨ G√©n√©ration Parcours...")
    prompt = f"""Expert p√©dagogique. Cr√©e un parcours pour ce cours: {course_text[:3000]}...
    JSON ATTENDU:
    {{
      "learning_content": "R√©sum√© Markdown...",
      "flashcards": [{{ "front": "Q", "back": "R" }}],
      "quiz": [{{ "question": "Q?", "options": ["A","B"], "correct_index": 0 }}],
      "practice_task": {{ "instruction": "Exercice...", "xp": 100 }}
    }}
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            response_format={"type": "json_object"},
            messages=[{"role": "user", "content": prompt}]
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        print(f"Error: {e}")
        return {}

def evaluate_student_answer(instruction: str, student_answer: str, course_context: str) -> dict:
    prompt = f"""Corrige en fran√ßais. Context: {course_context[:1000]}. Question: {instruction}. Reponse: {student_answer}.
    JSON: {{ "is_correct": bool, "feedback": "string", "score": int }}"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[{"role": "user", "content": prompt}]
    )
    return json.loads(response.choices[0].message.content)

def generate_daily_plan(goal: str, deadline: str, current_xp: int) -> dict:
    prompt = f"""Coach productivit√© FR. But: {goal}. Deadline: {deadline}.
    JSON: {{ "daily_message": "...", "quote": "...", "micro_tasks": [{{ "id": 1, "task": "...", "xp_reward": 20 }}] }}"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[{"role": "user", "content": prompt}]
    )
    return json.loads(response.choices[0].message.content)

def chat_with_tutor(history: List[dict], course_context: str) -> str:
    clean_history = [{"role": "system", "content": f"Tuteur Socratique FR. Contexte: {course_context[:3000]}"}]
    for msg in history:
        if msg.get("role") in ["user", "assistant"]:
            clean_history.append({"role": msg["role"], "content": str(msg["content"])})

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=clean_history
    )
    return response.choices[0].message.content

------------------------------

--- FICHIER : backend/src/studia/main.py (298 lignes) ---
"""
Studia API - MAIN APPLICATION (VERSION ROBUSTE)
"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Literal, List, Optional, Any, Dict
from datetime import datetime
import uuid
import traceback
import json

# --- IMPORTS ---
from .quiz_generator import quiz_generator_from_image, quiz_generator_from_text, extract_text
from .flashcard_generator import generate_flashcards
from .learning_path import (
    generate_mastery_path,
    evaluate_student_answer,
    generate_daily_plan,
    chat_with_tutor
)

app = FastAPI(title="Studia API", version="2.1.0")

# --- CORS (Tr√®s permissif pour √©viter les blocages) ---
origins = ["*"]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# MOD√àLES DE DONN√âES (S√©curis√©s avec Optional)
# ==========================================

# 1. Extraction
class ExtractTextRequest(BaseModel):
    images: List[str]

class ExtractedPage(BaseModel):
    pageNumber: int
    text: str
    wordCount: int

class ExtractTextResponse(BaseModel):
    totalImages: int
    pagesExtracted: int
    extractedText: str
    pages: List[ExtractedPage]

# 2. Quiz
class QuizGenerateRequest(BaseModel):
    image: str
    num_questions: int = 5
    difficulty: str = "medium"

class QuizGenerateFromTextRequest(BaseModel):
    course_text: str
    num_questions: int = 5
    difficulty: str = "medium"

class QuizQuestion(BaseModel):
    id: int
    question: str
    options: List[str]
    correctAnswer: int
    explanation: Optional[str] = ""

class QuizResponse(BaseModel):
    id: str
    questions: List[QuizQuestion]
    createdAt: str
    extractedText: Optional[str] = ""

# 3. Flashcards
class FlashcardGenerateRequest(BaseModel):
    course_text: str
    num_cards: int = 10
    difficulty: str = "medium"

class Flashcard(BaseModel):
    front: str
    back: str
    category: Optional[str] = "G√©n√©ral"
    difficulty: Optional[str] = "medium"

class FlashcardResponse(BaseModel):
    id: str
    flashcards: List[Flashcard]
    createdAt: str

# 4. Mode Parcours (S√âCURIS√â)
class MasteryRequest(BaseModel):
    course_text: str

class PathFlashcard(BaseModel):
    front: str
    back: str

class QuizItem(BaseModel):
    question: str
    options: List[str]
    correct_index: int

class PracticeTask(BaseModel):
    instruction: str
    xp: int

# On met tout en Optional pour √©viter le crash si l'IA oublie un champ
class MasteryResponse(BaseModel):
    learning_content: Optional[str] = "Contenu en cours de g√©n√©ration..."
    flashcards: Optional[List[PathFlashcard]] = []
    quiz: Optional[List[QuizItem]] = []
    practice_task: Optional[PracticeTask] = None

class EvaluateRequest(BaseModel):
    instruction: str
    student_answer: str
    course_context: str

class EvaluateResponse(BaseModel):
    is_correct: bool
    feedback: str
    score: int

class MotivationRequest(BaseModel):
    goal: str
    deadline: str
    current_xp: int = 0

class MotivationResponse(BaseModel):
    daily_message: str
    quote: str
    micro_tasks: List[dict]

class ChatRequest(BaseModel):
    message: str
    history: List[dict]
    course_context: str

class ChatResponse(BaseModel):
    reply: str

# ==========================================
# HELPERS
# ==========================================
def extract_base64_from_data_uri(data_uri: str) -> str:
    if "base64," in data_uri:
        return data_uri.split("base64,")[1]
    return data_uri

# ==========================================
# ENDPOINTS
# ==========================================

@app.get("/")
def root():
    return {"status": "online", "version": "2.1.0"}

# --- 1. EXTRACTION ---
@app.post("/api/extract-text", response_model=ExtractTextResponse)
async def extract_text_endpoint(request: ExtractTextRequest):
    try:
        print(f"üì∏ Extracting from {len(request.images)} images")
        combined_text = ""
        pages = []
        for i, img in enumerate(request.images):
            base64_img = extract_base64_from_data_uri(img)
            text = extract_text(base64_img)
            if not text: text = "[Texte illisible]"
            combined_text += text + "\n"
            pages.append(ExtractedPage(pageNumber=i+1, text=text, wordCount=len(text.split())))

        return ExtractTextResponse(
            totalImages=len(request.images),
            pagesExtracted=len(pages),
            extractedText=combined_text,
            pages=pages
        )
    except Exception as e:
        print(f"‚ùå Error Extract: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Extraction failed: {str(e)}")

# --- 2. QUIZ ---
@app.post("/api/quiz/generate-from-text", response_model=QuizResponse)
async def generate_quiz_from_text_endpoint(request: QuizGenerateFromTextRequest):
    try:
        print("üìù Generating Quiz...")
        quiz_data = quiz_generator_from_text(
            course_text=request.course_text,
            num_questions=request.num_questions,
            difficulty=request.difficulty,
            enable_refinement=True
        )

        questions = []
        for i, q in enumerate(quiz_data.get("questions", [])):
            questions.append(QuizQuestion(
                id=i+1,
                question=q.get("question", "Erreur question"),
                options=q.get("options", ["A", "B"]),
                correctAnswer=q.get("correctAnswer", 0),
                explanation=q.get("explanation", "")
            ))

        return QuizResponse(
            id=str(uuid.uuid4()),
            source="text",
            difficulty=request.difficulty,
            questions=questions,
            createdAt=datetime.now().isoformat(),
            extractedText=request.course_text
        )
    except Exception as e:
        print(f"‚ùå Error Quiz: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

# --- 3. FLASHCARDS ---
@app.post("/api/flashcards/generate", response_model=FlashcardResponse)
async def generate_flashcards_endpoint(request: FlashcardGenerateRequest):
    try:
        print("üé¥ Generating Flashcards...")
        data = generate_flashcards(request.course_text, request.num_cards, request.difficulty)
        cards = []
        for c in data.get("flashcards", []):
            cards.append(Flashcard(
                front=c.get("front", ""),
                back=c.get("back", ""),
                category=c.get("category", "G√©n√©ral"),
                difficulty=c.get("difficulty", "medium")
            ))

        return FlashcardResponse(
            id=str(uuid.uuid4()),
            flashcards=cards,
            createdAt=datetime.now().isoformat()
        )
    except Exception as e:
        print(f"‚ùå Error Flashcards: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

# --- 4. PARCOURS (ROBUSTE) ---
@app.post("/api/path/generate", response_model=MasteryResponse)
async def generate_path_endpoint(request: MasteryRequest):
    try:
        print("‚ö°Ô∏è Generating Path...")
        data = generate_mastery_path(request.course_text)

        # Si l'IA renvoie une erreur ou un JSON vide, on g√®re
        if not data:
            raise ValueError("AI returned empty response")

        # On construit la r√©ponse manuellement pour √©viter les erreurs de validation Pydantic
        return MasteryResponse(
            learning_content=data.get("learning_content", "Erreur de g√©n√©ration du contenu."),
            flashcards=data.get("flashcards", []),
            quiz=data.get("quiz", []),
            practice_task=data.get("practice_task", {"instruction": "Impossible de g√©n√©rer l'exercice.", "xp": 0})
        )

    except Exception as e:
        print(f"‚ùå Error Path: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

# --- 5. AUTRES ---
@app.post("/api/path/evaluate", response_model=EvaluateResponse)
async def evaluate_answer_endpoint(request: EvaluateRequest):
    try:
        return evaluate_student_answer(request.instruction, request.student_answer, request.course_context)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/motivation/generate", response_model=MotivationResponse)
async def generate_motivation_endpoint(request: MotivationRequest):
    try:
        return generate_daily_plan(request.goal, request.deadline, request.current_xp)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/chat/tutor", response_model=ChatResponse)
async def chat_tutor_endpoint(request: ChatRequest):
    try:
        reply = chat_with_tutor(request.history, request.course_context)
        return ChatResponse(reply=reply)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

------------------------------
