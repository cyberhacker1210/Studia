import json
import os
from typing import List
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def generate_diagnostic_quiz(course_text: str) -> dict:
    print("ðŸ§¬ GÃ©nÃ©ration Diagnostic...")
    prompt = f"""Tu es un expert pÃ©dagogique. CrÃ©e un quiz de diagnostic de 5 questions pour Ã©valuer la comprÃ©hension globale de ce cours.
    
    Chaque question doit tester un concept clÃ© diffÃ©rent.
    
    COURS : {course_text[:15000]}

    JSON ATTENDU :
    {{
      "questions": [
        {{
          "question": "...",
          "options": ["A","B","C","D"],
          "correct_index": 0,
          "explanation": "...",
          "concept": "Nom du concept testÃ© (ex: Dates, DÃ©finitions, Formules)"
        }}
      ]
    }}
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[{"role": "user", "content": prompt}]
    )
    return json.loads(response.choices[0].message.content)

def generate_remediation_content(course_text: str, weak_concepts: List[str], difficulty: int) -> dict:
    print(f"ðŸ’Š GÃ©nÃ©ration RemÃ©diation (Niveau {difficulty}) pour : {weak_concepts}")
    
    concepts_str = ", ".join(weak_concepts)
    
    prompt = f"""L'Ã©lÃ¨ve a Ã©chouÃ© sur les concepts suivants : {concepts_str}.
    
    1. RÃ©explique ces concepts de maniÃ¨re ultra-claire et pÃ©dagogique (style "C'est pas sorcier").
    2. CrÃ©e 3 flashcards spÃ©cifiques pour mÃ©moriser ces points.
    
    Niveau de difficultÃ© actuel : {difficulty}/3 (1=Basique, 3=Expert).
    
    COURS : {course_text[:15000]}

    JSON ATTENDU :
    {{
      "text": "Explication en Markdown...",
      "flashcards": [
        {{ "front": "Question/Concept", "back": "RÃ©ponse" }}
      ]
    }}
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[{"role": "user", "content": prompt}]
    )
    return json.loads(response.choices[0].message.content)

def generate_validation_quiz(course_text: str, concepts: List[str], difficulty: int) -> dict:
    print(f"ðŸŽ¯ GÃ©nÃ©ration Validation (Niveau {difficulty})...")
    
    focus_instruction = ""
    if concepts:
        focus_instruction = f"Concentre les questions sur ces concepts : {', '.join(concepts)}."
    
    difficulty_prompt = ""
    if difficulty == 1: difficulty_prompt = "Questions simples et directes."
    elif difficulty == 2: difficulty_prompt = "Questions piÃ¨ges ou d'application."
    elif difficulty == 3: difficulty_prompt = "Questions complexes demandant de la rÃ©flexion."

    prompt = f"""CrÃ©e un quiz de validation de 5 questions.
    {focus_instruction}
    {difficulty_prompt}
    
    COURS : {course_text[:15000]}

    JSON ATTENDU :
    {{
      "questions": [
        {{
          "question": "...",
          "options": ["..."],
          "correct_index": 0,
          "explanation": "...",
          "concept": "..."
        }}
      ]
    }}
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[{"role": "user", "content": prompt}]
    )
    return json.loads(response.choices[0].message.content)

# ... (Garder les autres fonctions existantes comme chat_with_tutor) ...
def chat_with_tutor(history: List[dict], course_context: str) -> str:
    clean_history = [{"role": "system", "content": f"Tuteur Socratique. Contexte: {course_context[:3000]}"}]
    for msg in history:
        if msg.get("role") in ["user", "assistant"]:
            clean_history.append({"role": msg["role"], "content": str(msg["content"])})

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=clean_history
    )
    return response.choices[0].message.content