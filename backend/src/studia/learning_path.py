"""
Learning Path Generator - Full Version
"""
import json
import os
from typing import List, Dict, Any
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# --- 1. FONCTION PRINCIPALE (Celle qui manquait) ---
def generate_mastery_path(course_text: str) -> dict:
    """
    GÃ©nÃ¨re le parcours complet en 3 modules (Micro-Learning)
    AppelÃ© par /api/path/generate
    """
    print("ðŸ§¬ GÃ©nÃ©ration Parcours Micro-Learning (Map)...")

    prompt = f"""Tu es un architecte pÃ©dagogique. DÃ©coupe ce cours en 3 modules progressifs pour un apprentissage sur 3 jours.

    COURS (Extrait) :
    {course_text[:15000]}

    FORMAT JSON ATTENDU (Strictement) :
    {{
      "modules": [
        {{
          "title": "Jour 1 : Les Bases",
          "description": "Comprendre les concepts clÃ©s.",
          "content": "RÃ©sumÃ© clair en Markdown...",
          "quiz": [
             {{ "question": "...", "options": ["A","B"], "correct_index": 0, "explanation": "..." }}
          ]
        }},
        {{
          "title": "Jour 2 : Approfondissement",
          "description": "Analyse dÃ©taillÃ©e.",
          "content": "Contenu dÃ©taillÃ© en Markdown...",
          "quiz": [ ... ]
        }},
        {{
          "title": "Jour 3 : MaÃ®trise",
          "description": "Application et synthÃ¨se.",
          "content": "SynthÃ¨se finale en Markdown...",
          "quiz": [ ... ]
        }}
      ]
    }}

    RÃˆGLES :
    - 3 Modules exactement.
    - Chaque module a 2 questions de quiz.
    - RÃ©ponds UNIQUEMENT en JSON valide.
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            response_format={"type": "json_object"},
            messages=[{"role": "user", "content": prompt}]
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        print(f"Error generate_mastery_path: {e}")
        # Fallback en cas d'erreur pour ne pas crasher le front
        return {
            "modules": [
                {
                    "title": "Module 1 (Erreur IA)",
                    "description": "Impossible de gÃ©nÃ©rer le contenu.",
                    "content": "DÃ©solÃ©, une erreur est survenue. RÃ©essayez.",
                    "quiz": []
                }
            ]
        }


# --- 2. FONCTIONS ADAPTATIVES (Diagnostic/Remediation) ---

def generate_diagnostic_quiz(course_text: str) -> dict:
    print("ðŸ§¬ GÃ©nÃ©ration Diagnostic...")
    prompt = f"""CrÃ©e un quiz de diagnostic de 5 questions.
    COURS : {course_text[:15000]}
    JSON : {{ "questions": [ {{ "question": "...", "options": ["..."], "correct_index": 0, "explanation": "...", "concept": "..." }} ] }}
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[{"role": "user", "content": prompt}]
    )
    return json.loads(response.choices[0].message.content)


def generate_remediation_content(course_text: str, weak_concepts: List[str], difficulty: int) -> dict:
    print(f"ðŸ’Š GÃ©nÃ©ration RemÃ©diation pour : {weak_concepts}")
    concepts_str = ", ".join(weak_concepts)

    prompt = f"""Explique ces concepts ratÃ©s : {concepts_str}.
    Niveau : {difficulty}/3.
    COURS : {course_text[:15000]}
    JSON : {{ "text": "Markdown...", "flashcards": [ {{ "front": "...", "back": "..." }} ] }}
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[{"role": "user", "content": prompt}]
    )
    return json.loads(response.choices[0].message.content)


def generate_validation_quiz(course_text: str, concepts: List[str], difficulty: int) -> dict:
    print(f"ðŸŽ¯ GÃ©nÃ©ration Validation (Niveau {difficulty})...")
    prompt = f"""Quiz de validation 5 questions. Niveau {difficulty}.
    Concepts : {concepts}
    COURS : {course_text[:15000]}
    JSON : {{ "questions": [ {{ "question": "...", "options": ["..."], "correct_index": 0, "explanation": "...", "concept": "..." }} ] }}
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[{"role": "user", "content": prompt}]
    )
    return json.loads(response.choices[0].message.content)


# --- 3. FONCTIONS UTILITAIRES ---

def evaluate_student_answer(instruction: str, student_answer: str, course_context: str) -> dict:
    prompt = f"""Corrige. Context: {course_context[:1000]}. Q: {instruction}. R: {student_answer}.
    JSON: {{ "is_correct": bool, "feedback": "string", "score": int }}"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[{"role": "user", "content": prompt}]
    )
    return json.loads(response.choices[0].message.content)


def generate_daily_plan(goal: str, deadline: str, current_xp: int) -> dict:
    prompt = f"""Coach productivitÃ©. But: {goal}. Deadline: {deadline}.
    JSON: {{ "daily_message": "...", "quote": "...", "micro_tasks": [{{ "id": 1, "task": "...", "xp_reward": 20 }}] }}"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[{"role": "user", "content": prompt}]
    )
    return json.loads(response.choices[0].message.content)


def chat_with_tutor(history: List[dict], course_context: str) -> str:
    clean_history = [{"role": "system", "content": f"Tuteur Socratique. Contexte: {course_context[:3000]}"}]
    for msg in history:
        if msg.get("role") in ["user", "assistant"]:
            clean_history.append({"role": msg["role"], "content": str(msg["content"])})

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=clean_history
    )
    return response.choices[0].message.content