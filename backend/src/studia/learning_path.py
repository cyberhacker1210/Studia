"""
Learning Path Generator - Micro-Learning Version
"""
import json
import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def generate_mastery_path(course_text: str) -> dict:
    print("üß¨ G√©n√©ration Parcours Micro-Learning...")

    prompt = f"""Tu es un architecte p√©dagogique expert (style Brilliant.org).
    
    TA MISSION :
    D√©coupe ce cours en 3 modules progressifs pour un apprentissage sur 3 jours.
    Chaque module doit √™tre court, percutant et interactif.

    LE COURS :
    {course_text[:15000]} (tronqu√© si trop long)

    FORMAT JSON ATTENDU :
    {{
      "modules": [
        {{
          "title": "Jour 1 : Les Fondamentaux",
          "description": "Comprendre les concepts cl√©s.",
          "content": "Explication claire et concise (Markdown)...",
          "quiz": [
             {{ "question": "...", "options": ["A","B"], "correct_index": 0, "explanation": "..." }}
          ]
        }},
        {{
          "title": "Jour 2 : Analyse & M√©canismes",
          "description": "Comment √ßa marche en d√©tail.",
          "content": "Explication approfondie (Markdown)...",
          "quiz": [ ... ]
        }},
        {{
          "title": "Jour 3 : Application & Synth√®se",
          "description": "Mise en pratique et ma√Ætrise.",
          "content": "Synth√®se et cas concrets (Markdown)...",
          "quiz": [ ... ]
        }}
      ]
    }}

    R√àGLES :
    1. Le contenu doit √™tre p√©dagogique, tutoyant l'√©l√®ve.
    2. Chaque module doit avoir exactement 2 questions de quiz pour v√©rifier la compr√©hension imm√©diate.
    3. JSON pur uniquement.
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            response_format={"type": "json_object"},
            messages=[{"role": "user", "content": prompt}]
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        print(f"Error: {e}")
        return {"modules": []}

# Les autres fonctions (evaluate_student_answer, etc.) restent inchang√©es...
def evaluate_student_answer(instruction: str, student_answer: str, course_context: str) -> dict:
    prompt = f"""Corrige en fran√ßais. Context: {course_context[:1000]}. Question: {instruction}. Reponse: {student_answer}.
    JSON: {{ "is_correct": bool, "feedback": "string", "score": int }}"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[{"role": "user", "content": prompt}]
    )
    return json.loads(response.choices[0].message.content)

def chat_with_tutor(history: list, course_context: str) -> str:
    clean_history = [{"role": "system", "content": f"Tuteur Socratique FR. Contexte: {course_context[:3000]}"}]
    for msg in history:
        if msg.get("role") in ["user", "assistant"]:
            clean_history.append({"role": msg["role"], "content": str(msg["content"])})

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=clean_history
    )
    return response.choices[0].message.content

def generate_daily_plan(goal: str, deadline: str, current_xp: int) -> dict:
    return {} # Placeholder si non utilis√©