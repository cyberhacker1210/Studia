import json
import os
from typing import List, Literal
from pydantic import BaseModel, Field
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# --- MOD√àLES DE DONN√âES (STRUCTURED OUTPUTS) ---

class Concept(BaseModel):
    name: str = Field(description="Nom du concept cl√© √©valu√©.")


class QuizQuestionAdaptive(BaseModel):
    question: str = Field(description="La question pos√©e.")
    options: List[str] = Field(description="4 choix de r√©ponse.", min_length=4, max_length=4)
    correct_index: int = Field(description="Index de la bonne r√©ponse (0-3).")
    explanation: str = Field(description="Explication p√©dagogique.")
    concept: str = Field(description="Le concept cl√© test√© par cette question (ex: 'Loi de l'offre', 'Cellule').")


class DiagnosticResult(BaseModel):
    questions: List[QuizQuestionAdaptive]


class RemediationContent(BaseModel):
    summary: str = Field(description="Un cours court et cibl√© sur les points faibles (Markdown).")
    flashcards: List[dict] = Field(description="Liste de flashcards {front, back} pour m√©moriser ces points.")


class PracticeExercise(BaseModel):
    instruction: str = Field(description="L'√©nonc√© de l'exercice (cas pratique, probl√®me, r√©daction).")
    context: str = Field(description="Contexte ou donn√©es n√©cessaires pour r√©pondre.")
    difficulty: Literal['easy', 'hard']


class EvaluationResult(BaseModel):
    is_correct: bool = Field(description="Si la r√©ponse est globalement satisfaisante.")
    score: int = Field(description="Note sur 100.")
    feedback: str = Field(description="Feedback d√©taill√© et constructif.")
    correction: str = Field(description="La r√©ponse id√©ale attendue.")


# --- FONCTIONS ---

def generate_diagnostic_quiz(course_text: str) -> dict:
    """√âTAPE 1 : G√©n√®re un quiz large pour tester tous les aspects du cours."""
    print("üß¨ G√©n√©ration Diagnostic...")

    prompt = "Tu es un √©valuateur. Cr√©e un quiz diagnostique de 10 questions couvrant TOUT le cours pour identifier les lacunes."

    completion = client.beta.chat.completions.parse(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": course_text[:20000]}
        ],
        response_format=DiagnosticResult,
    )
    return completion.choices[0].message.parsed.model_dump()


def generate_remediation_content(course_text: str, weak_concepts: List[str], difficulty: int = 1) -> dict:
    """√âTAPE 2 : G√©n√®re du contenu sp√©cifique sur les points faibles."""
    print(f"üíä G√©n√©ration Rem√©diation pour : {weak_concepts}")

    prompt = f"""L'√©l√®ve a √©chou√© sur ces concepts : {', '.join(weak_concepts)}.
    Cr√©e un module de rattrapage :
    1. Un r√©sum√© clair expliquant CES concepts sp√©cifiques.
    2. Des flashcards pour m√©moriser CES concepts.
    Niveau de profondeur : {difficulty}/3.
    """

    # On utilise un sch√©ma ad-hoc pour structurer la r√©ponse
    class RemediationSchema(BaseModel):
        text: str = Field(description="Le cours de rattrapage en Markdown.")
        flashcards: List[dict] = Field(description="Liste de {front: str, back: str}")

    completion = client.beta.chat.completions.parse(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": course_text[:20000]}
        ],
        response_format=Rem√©diationSchema,
    )
    return completion.choices[0].message.parsed.model_dump()


def generate_validation_quiz(course_text: str, concepts: List[str], difficulty: int) -> dict:
    """√âTAPE 3 : Quiz cibl√© et plus dur sur les concepts revus."""
    print("üéØ G√©n√©ration Quiz Validation...")

    level_desc = "facile" if difficulty == 1 else "interm√©diaire" if difficulty == 2 else "tr√®s difficile/pi√©geux"

    prompt = f"""Cr√©e un quiz de 5 questions TR√àS CIBL√âES sur ces concepts : {', '.join(concepts)}.
    Niveau : {level_desc}.
    Le but est de v√©rifier la ma√Ætrise totale."""

    completion = client.beta.chat.completions.parse(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": course_text[:20000]}
        ],
        response_format=DiagnosticResult,  # On r√©utilise la structure de quiz
    )
    return completion.choices[0].message.parsed.model_dump()


def generate_practice_exercise(course_text: str, difficulty: str) -> dict:
    """√âTAPE 4 & 6 : G√©n√®re un exercice pratique (Facile ou Difficile)."""
    print(f"üèãÔ∏è G√©n√©ration Exercice ({difficulty})...")

    prompt = f"""Cr√©e un exercice pratique de type 'Cas concret' ou 'Probl√®me √† r√©soudre' bas√© sur ce cours.
    Difficult√© : {difficulty}.
    L'exercice doit demander de la r√©flexion et de la r√©daction, pas juste un QCM."""

    completion = client.beta.chat.completions.parse(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": course_text[:20000]}
        ],
        response_format=PracticeExercise,
    )
    return completion.choices[0].message.parsed.model_dump()


def evaluate_student_answer(instruction: str, student_answer: str, course_context: str) -> dict:
    """√âTAPE 5 : Correction et Feedback."""
    print("üìù Correction Exercice...")

    prompt = """Tu es un prof correcteur. √âvalue la r√©ponse de l'√©tudiant par rapport √† l'√©nonc√© et au cours.
    Sois bienveillant mais rigoureux. Donne la correction parfaite √† la fin."""

    completion = client.beta.chat.completions.parse(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user",
             "content": f"COURS: {course_context[:10000]}\n\nCONSIGNE: {instruction}\n\nR√âPONSE √âL√àVE: {student_answer}"}
        ],
        response_format=EvaluationResult,
    )
    return completion.choices[0].message.parsed.model_dump()


# Fonction Chat standard pour le contexte "Tuteur" pendant l'exercice
def chat_with_tutor(history: list, course_context: str, current_message: str) -> str:
    messages = [{"role": "system",
                 "content": f"Tu es un tuteur p√©dagogique. Aide l'√©l√®ve sur ce cours : {course_context[:5000]}. Sois concis."}]
    for msg in history[-6:]: messages.append(msg)
    messages.append({"role": "user", "content": current_message})

    res = client.chat.completions.create(model="gpt-4o-mini", messages=messages)
    return res.choices[0].message.content